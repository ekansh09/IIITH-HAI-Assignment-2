{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS Bowl Semantic Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekansh09/IIITH-HAI-Assignment-2/blob/main/DS_Bowl_Semantic_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdlLBmOPKmd2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "from PIL import Image, GdImageFile\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "import tifffile as tiff\n",
        "from skimage.transform import resize\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk-h6lYlxFaN"
      },
      "source": [
        "## Data Science Bowl - 2018\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5rKkuZBSBBw",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "3f64267f-6cb0-423f-ac0a-55fdcadf3127"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-63da0173-a05e-442e-8298-970d2ec50a42\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-63da0173-a05e-442e-8298-970d2ec50a42\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ekanshchauhan\",\"key\":\"4394049147c3c92aab2cd971c57d4a7d\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su2nRf_zyfT1"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2TbrQaGhFb7",
        "outputId": "f44a48e8-858b-4529-f414-8f2274edb603"
      },
      "source": [
        "!kaggle competitions download -c data-science-bowl-2018"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data-science-bowl-2018.zip to /content\n",
            " 99% 355M/358M [00:01<00:00, 268MB/s]\n",
            "100% 358M/358M [00:01<00:00, 278MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo7Rl9vFlI3m",
        "outputId": "ecd0bf41-63bd-4d22-f6dc-13d41a7c1fd1"
      },
      "source": [
        "!unzip \"/content/data-science-bowl-2018.zip\" -d \"/content/data-science-bowl-2018/\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/data-science-bowl-2018.zip\n",
            "  inflating: /content/data-science-bowl-2018/stage1_sample_submission.csv.zip  \n",
            "  inflating: /content/data-science-bowl-2018/stage1_solution.csv.zip  \n",
            "  inflating: /content/data-science-bowl-2018/stage1_test.zip  \n",
            "  inflating: /content/data-science-bowl-2018/stage1_train.zip  \n",
            "  inflating: /content/data-science-bowl-2018/stage1_train_labels.csv.zip  \n",
            "  inflating: /content/data-science-bowl-2018/stage2_sample_submission_final.csv.zip  \n",
            "  inflating: /content/data-science-bowl-2018/stage2_test_final.zip  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvd26VRZnINH"
      },
      "source": [
        "!unzip \"/content/data-science-bowl-2018/stage1_train.zip\" -d \"/content/stage1_train\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxykxl-KS61j"
      },
      "source": [
        "train_ids = next(os.walk('./stage1_train'))[1]\n",
        "TRAIN_PATH=\"/content/stage1_train/\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvBzSVMD0vxr",
        "outputId": "9fa19b64-9503-4315-e11e-9abb71bc86ea"
      },
      "source": [
        "X_temp = []\n",
        "Y_temp = []\n",
        "\n",
        "for id_ in tqdm(train_ids):\n",
        "    path = TRAIN_PATH + str(id_)\n",
        "    img = cv2.imread(path +\"/images/\" + str(id_) + '.png', cv2.IMREAD_COLOR)\n",
        "    resized_img = cv2.resize(img,(256, 256), interpolation = cv2.INTER_CUBIC)\n",
        "    X_temp.append(resized_img)\n",
        "    mask = np.zeros((256, 256), dtype=np.bool)    \n",
        "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
        "        mask_ = cv2.imread(path + '/masks/' + mask_file, cv2.IMREAD_GRAYSCALE) \n",
        "        resized_mask = cv2.resize(mask_,(256, 256), interpolation = cv2.INTER_CUBIC)\n",
        "        mask = np.maximum(mask, resized_mask)\n",
        "    Y_temp.append(mask)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 670/670 [00:30<00:00, 22.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_sODmNHLti_"
      },
      "source": [
        "## Pre-Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pR_cWYfLvl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ad725d-a4d9-4083-f479-68e9c71742ce"
      },
      "source": [
        "print(len(X_temp))\n",
        "print(len(Y_temp))\n",
        "\n",
        "X = np.array(X_temp)\n",
        "Y = np.array(Y_temp)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
        "Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
        "\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "Y_train = Y_train / 255\n",
        "Y_test = Y_test / 255\n",
        "\n",
        "\n",
        "Y_train = np.round(Y_train,0)\t\n",
        "Y_test = np.round(Y_test,0)\t\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "670\n",
            "670\n",
            "(536, 256, 256, 3)\n",
            "(536, 256, 256, 1)\n",
            "(134, 256, 256, 3)\n",
            "(134, 256, 256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eImaD2Ppzvbn"
      },
      "source": [
        "##MultiResUNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVVNvxl4LviK"
      },
      "source": [
        "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
        "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
        "    x = BatchNormalization( scale=False)(x)\n",
        "    if(activation == None):\n",
        "        return x\n",
        "    x = Activation(activation, name=name)(x)\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLxBIZKTMLEy"
      },
      "source": [
        "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2)):\n",
        "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization(scale=False)(x)\n",
        "    return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iod2ayD9MOvy"
      },
      "source": [
        "def MultiResBlock(U, inp, alpha = 1.67):\n",
        "\n",
        "    W = alpha * U\n",
        "    shortcut = inp\n",
        "\n",
        "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +  int(W*0.5), 1, 1, activation=None, padding='same')\n",
        "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3, activation='relu', padding='same')\n",
        "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3, activation='relu', padding='same')\n",
        "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3, activation='relu', padding='same')\n",
        "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
        "    out = BatchNormalization()(out)\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization()(out)\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx7vud2cMmkT"
      },
      "source": [
        "def ResPath(filters, length, inp):\n",
        "    shortcut = inp\n",
        "    shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')\n",
        "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization()(out)\n",
        "\n",
        "    for i in range(length-1):\n",
        "        shortcut = out\n",
        "        shortcut = conv2d_bn(shortcut, filters, 1, 1, activation=None, padding='same')\n",
        "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
        "        out = add([shortcut, out])\n",
        "        out = Activation('relu')(out)\n",
        "        out = BatchNormalization()(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilO44zK-Mu1s"
      },
      "source": [
        "def MultiResUnet(height, width, n_channels):\n",
        "\n",
        "    inputs = Input((height, width, n_channels))\n",
        "    \n",
        "    mresblock1 = MultiResBlock(32, inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
        "    mresblock1 = ResPath(32, 4, mresblock1)\n",
        "\n",
        "    mresblock2 = MultiResBlock(32*2, pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
        "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
        "\n",
        "    mresblock3 = MultiResBlock(32*4, pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
        "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
        "\n",
        "    mresblock4 = MultiResBlock(32*8, pool3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
        "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
        "\n",
        "    mresblock5 = MultiResBlock(32*16, pool4)\n",
        "\n",
        "    up6 = concatenate([trans_conv2d_bn(mresblock5,32*8, 2, 2), mresblock4])\n",
        "    mresblock6 = MultiResBlock(32*8, up6)\n",
        "\n",
        "    up7 = concatenate([trans_conv2d_bn(mresblock6, 32*4, 2, 2), mresblock3])\n",
        "    mresblock7 = MultiResBlock(32*4, up7)\n",
        "\n",
        "    up8 = concatenate([trans_conv2d_bn(mresblock7, 32*2, 2, 2), mresblock2])\n",
        "    mresblock8 = MultiResBlock(32*2, up8)\n",
        "\n",
        "    up9 = concatenate([trans_conv2d_bn(mresblock8, 32, 2, 2), mresblock1])\n",
        "    mresblock9 = MultiResBlock(32, up9)\n",
        "\n",
        "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
        "    \n",
        "    \n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "                  \n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB4M0xQKz1EN"
      },
      "source": [
        "##Metrics (Dice, Jaccard)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rFV863jSsK5"
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1.0\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ1knZz8NJfT"
      },
      "source": [
        "def jacard(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "    return intersection/union"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAEcGJxEz6yP"
      },
      "source": [
        "##Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AP49k7nPLb-"
      },
      "source": [
        "def saveModel(model):\n",
        "\n",
        "    model_json = model.to_json()\n",
        "\n",
        "    try:\n",
        "        os.makedirs('models')\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    fp = open('models/modelP.json','w')\n",
        "    fp.write(model_json)\n",
        "    model.save_weights('models/modelW.h5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xjS3YACz9yb"
      },
      "source": [
        "##Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsTNGMM0NOxy"
      },
      "source": [
        "def evaluateModel(model, X_test, Y_test, batchSize):\n",
        "    \n",
        "    try:\n",
        "        os.makedirs('results')\n",
        "    except:\n",
        "        pass \n",
        "    \n",
        "\n",
        "    yp = model.predict(x=X_test,batch_size=batchSize, verbose=1)\n",
        "    print('Min : '+ str(np.min(yp)))\n",
        "    print('Max : '+ str(np.max(yp)))\n",
        "    yp = np.round_(yp,0)\n",
        "    print('Unique after rounding : '+ str(np.unique(yp)))\n",
        "    # print(yp)\n",
        "\n",
        "    for i in range(6):\n",
        "        \n",
        "        plt.figure(figsize=(20,4))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.imshow(X_test[i], cmap='gray')\n",
        "        plt.title('Input')\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1])*255, cmap='gray')\n",
        "        plt.title('Ground Truth')\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1])*255, cmap='gray')\n",
        "        plt.title('Prediction')\n",
        "        intersection1 = yp[i].ravel() * Y_test[i].ravel()\n",
        "        # plt.show()\n",
        "        union1 = yp[i].ravel() + Y_test[i].ravel() - intersection1\n",
        "        # plt.show()\n",
        "\n",
        "        jacard = (np.sum(intersection1)/np.sum(union1))  \n",
        "        plt.suptitle('Jacard Index'+ str(np.sum(intersection1)) +'/'+ str(np.sum(union1)) +'='+str(jacard))\n",
        "\n",
        "        plt.savefig('results/'+str(i)+'.png',format='png')\n",
        "        plt.show()\n",
        "\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "    jacard = 0\n",
        "    dice = 0\n",
        "    \n",
        "    \n",
        "    for i in range(len(Y_test)):\n",
        "        yp_2 = yp[i].ravel()\n",
        "        y2 = Y_test[i].ravel()\n",
        "        \n",
        "        intersection = yp_2 * y2\n",
        "        union = yp_2 + y2 - intersection\n",
        "\n",
        "        jacard += (np.sum(intersection)/np.sum(union))  \n",
        "\n",
        "        dice += (2. * np.sum(intersection) + 1) / (np.sum(yp_2) + np.sum(y2) + 1)\n",
        "\n",
        "    \n",
        "    jacard /= len(Y_test)\n",
        "    dice /= len(Y_test)\n",
        "    \n",
        "\n",
        "\n",
        "    print('Jacard Index : '+str(jacard))\n",
        "    print('Dice Coefficient : '+str(dice))\n",
        "    \n",
        "\n",
        "    fp = open('models/log.txt','a')\n",
        "    fp.write(str(jacard)+'\\n')\n",
        "    fp.close()\n",
        "\n",
        "    fp = open('models/best.txt','r')\n",
        "    best = fp.read()\n",
        "    fp.close()\n",
        "\n",
        "    if(jacard>float(best)):\n",
        "        print('***********************************************')\n",
        "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
        "        print('***********************************************')\n",
        "        fp = open('models/best.txt','w')\n",
        "        fp.write(str(jacard))\n",
        "        fp.close()\n",
        "\n",
        "        saveModel(model)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10K1LzW90KgB"
      },
      "source": [
        "##Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEbnKM8qN4c2"
      },
      "source": [
        "def trainStep(model, X_train, Y_train, X_test, Y_test, epochs, batchSize):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      print('Epoch : {}'.format(epoch+1))\n",
        "      model.fit(X_train, Y_train, epochs=1, verbose=1, batch_size=batchSize)     \n",
        "      evaluateModel(model,X_test, Y_test, batchSize)\n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YGKFqtfnQLK"
      },
      "source": [
        "##UNet ++"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhh1ToQHnCrG"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Concatenate, UpSampling2D, Input\n",
        "import random\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5w92t9G5FJ-c"
      },
      "source": [
        "\n",
        "dropout_rate = 0.5\n",
        "act = \"relu\"\n",
        "\n",
        "def standard_unit(input_tensor, nb_filter, kernel_size=3):\n",
        "\n",
        "    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(input_tensor)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def UNetPlusPlus(input_size):\n",
        "\n",
        "    nb_filter = [32,64,128,256,512]\n",
        "\n",
        "    img_input = Input(input_size)\n",
        "\n",
        "\n",
        "\n",
        "    conv1_1 = standard_unit(img_input, nb_filter=nb_filter[0])\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1_1)\n",
        "\n",
        "    conv2_1 = standard_unit(pool1,nb_filter=nb_filter[1])\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2_1)\n",
        "\n",
        "    up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), padding='same')(conv2_1)\n",
        "    conv1_2 = concatenate([up1_2, conv1_1])\n",
        "    conv1_2 = standard_unit(conv1_2, nb_filter=nb_filter[0])\n",
        "\n",
        "    conv3_1 = standard_unit(pool2, nb_filter=nb_filter[2])\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3_1)\n",
        "\n",
        "    up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), padding='same')(conv3_1)\n",
        "    conv2_2 = concatenate([up2_2, conv2_1])\n",
        "    conv2_2 = standard_unit(conv2_2, nb_filter=nb_filter[1])\n",
        "\n",
        "    up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), padding='same')(conv2_2)\n",
        "    conv1_3 = concatenate([up1_3, conv1_1, conv1_2])\n",
        "    conv1_3 = standard_unit(conv1_3, nb_filter=nb_filter[0])\n",
        "\n",
        "    conv4_1 = standard_unit(pool3, nb_filter=nb_filter[3])\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4_1)\n",
        "\n",
        "    up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), padding='same')(conv4_1)\n",
        "    conv3_2 = concatenate([up3_2, conv3_1])\n",
        "    conv3_2 = standard_unit(conv3_2, nb_filter=nb_filter[2])\n",
        "\n",
        "    up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), padding='same')(conv3_2)\n",
        "    conv2_3 = concatenate([up2_3, conv2_1, conv2_2])\n",
        "    conv2_3 = standard_unit(conv2_3, nb_filter=nb_filter[1])\n",
        "\n",
        "    up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), padding='same')(conv2_3)\n",
        "    conv1_4 = concatenate([up1_4, conv1_1, conv1_2, conv1_3])\n",
        "    conv1_4 = standard_unit(conv1_4, nb_filter=nb_filter[0])\n",
        "\n",
        "    conv5_1 = standard_unit(pool4, nb_filter=nb_filter[4])\n",
        "\n",
        "    up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), padding='same')(conv5_1)\n",
        "    conv4_2 = concatenate([up4_2, conv4_1])\n",
        "    conv4_2 = standard_unit(conv4_2, nb_filter=nb_filter[3])\n",
        "\n",
        "    up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), padding='same')(conv4_2)\n",
        "    conv3_3 = concatenate([up3_3, conv3_1, conv3_2])\n",
        "    conv3_3 = standard_unit(conv3_3, nb_filter=nb_filter[2])\n",
        "\n",
        "    up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), padding='same')(conv3_3)\n",
        "    conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3])\n",
        "    conv2_4 = standard_unit(conv2_4, nb_filter=nb_filter[1])\n",
        "\n",
        "    up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), padding='same')(conv2_4)\n",
        "    conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4])\n",
        "    conv1_5 = standard_unit(conv1_5, nb_filter=nb_filter[0])\n",
        "\n",
        "    nestnet_output_4 = Conv2D(1, (1, 1), activation='sigmoid', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_5)\n",
        " \n",
        "    model = Model(inputs=img_input, outputs=[nestnet_output_4])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdEFUovr0Ynb"
      },
      "source": [
        "##UNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwp3pGw8nFT4"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    \"\"\" Outputs \"\"\"\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    model = Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AnVB6oO0f37"
      },
      "source": [
        "##Calling Models (UNet, UNet++, MultiResUNet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXY5mXmy0mk5"
      },
      "source": [
        "# model = build_unet((256,256,3))\n",
        "# model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[dice_coef, jacard, 'accuracy'])\n",
        "# saveModel(model)\n",
        "# model.summary()     "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBbN5Qm14lPn"
      },
      "source": [
        "# model = UNetPlusPlus((256,256,3))\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, 'accuracy'])\n",
        "\n",
        "# saveModel(model)\n",
        "# model.summary()   "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqUAYR0d0P3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d748fc4-b715-4e2b-c35a-ad509550f6dd"
      },
      "source": [
        "model = MultiResUnet(height=256, width=256, n_channels=3)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, 'accuracy'])\n",
        "\n",
        "saveModel(model)\n",
        "model.summary()   "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 8)  216         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 8)  24          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 256, 256, 8)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 17) 1224        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 17) 51          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 256, 256, 17) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 256, 256, 26) 3978        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 256, 256, 26) 78          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 256, 256, 26) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 256, 256, 51) 153         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256, 256, 51) 0           activation[0][0]                 \n",
            "                                                                 activation_1[0][0]               \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 256, 256, 51) 153         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 256, 256, 51) 204         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 256, 256, 51) 0           batch_normalization[0][0]        \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 256, 256, 51) 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 256, 256, 51) 204         activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 128, 128, 51) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 128, 128, 17) 7803        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 128, 128, 17) 51          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 128, 128, 17) 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 35) 5355        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 128, 128, 35) 105         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 128, 128, 35) 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 53) 16695       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 128, 128, 53) 159         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 128, 128, 53) 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 128, 128, 105 5355        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128, 128, 105 0           activation_12[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 128, 128, 105 315         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 128, 128, 105 420         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 128, 128, 105 0           batch_normalization_18[0][0]     \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 128, 128, 105 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 128, 128, 105 420         activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 105)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 64, 64, 35)   33075       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 64, 64, 35)   105         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 64, 64, 35)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 64, 64, 71)   22365       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 64, 64, 71)   213         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 64, 64, 71)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 64, 64, 106)  67734       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 64, 64, 106)  318         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 64, 64, 106)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 64, 64, 212)  22260       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 212)  0           activation_22[0][0]              \n",
            "                                                                 activation_23[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 64, 64, 212)  636         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 64, 64, 212)  848         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 64, 64, 212)  0           batch_normalization_33[0][0]     \n",
            "                                                                 batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 64, 64, 212)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 64, 64, 212)  848         activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 212)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 71)   135468      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 32, 32, 71)   213         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 32, 32, 71)   0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 142)  90738       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 32, 32, 142)  426         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 32, 32, 142)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 32, 213)  272214      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 32, 32, 213)  639         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 32, 213)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 426)  90312       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 426)  0           activation_30[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 32, 32, 426)  1278        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 32, 32, 426)  1704        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 32, 32, 426)  0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 32, 426)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 32, 32, 426)  1704        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 426)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 142)  544428      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 16, 16, 142)  426         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 142)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 284)  362952      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 16, 16, 284)  852         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 284)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 427)  1091412     activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 16, 16, 427)  1281        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 16, 16, 427)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 853)  363378      max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 16, 16, 853)  0           activation_36[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 16, 16, 853)  2559        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 16, 16, 853)  3412        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 32, 32, 256)  981504      batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 16, 16, 853)  0           batch_normalization_54[0][0]     \n",
            "                                                                 batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 32, 32, 256)  109056      batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 32, 32, 256)  768         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 16, 16, 853)  0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 32, 32, 256)  768         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 32, 32, 256)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 16, 16, 853)  3412        activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 32, 32, 256)  0           batch_normalization_51[0][0]     \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 32, 32, 256)  873728      batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 32, 32, 256)  0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 32, 32, 256)  768         conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 32, 32, 256)  1024        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 512)  0           batch_normalization_60[0][0]     \n",
            "                                                                 batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 32, 32, 71)   327168      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 32, 32, 71)   213         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 32, 32, 71)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 32, 32, 142)  90738       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 32, 32, 142)  426         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 64, 64, 128)  244224      batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 32, 32, 142)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 64, 64, 128)  27136       batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 64, 64, 128)  384         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 32, 32, 213)  272214      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 64, 64, 128)  384         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 64, 64, 128)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 32, 32, 213)  639         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 64, 64, 128)  0           batch_normalization_39[0][0]     \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 32, 32, 213)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 64, 64, 128)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 32, 32, 426)  218112      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 426)  0           activation_40[0][0]              \n",
            "                                                                 activation_41[0][0]              \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 64, 64, 128)  512         activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 32, 32, 426)  1278        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 32, 32, 426)  1704        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 64, 64, 128)  147456      batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 32, 32, 426)  0           batch_normalization_61[0][0]     \n",
            "                                                                 batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 64, 64, 128)  16384       batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 64, 64, 128)  384         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 32, 32, 426)  0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 64, 64, 128)  384         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 64, 64, 128)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 32, 32, 426)  1704        activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 64, 64, 128)  0           batch_normalization_42[0][0]     \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 128)  218240      batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 64, 64, 128)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 64, 64, 128)  384         conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 64, 64, 128)  512         activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 128, 128, 64) 60480       batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_67[0][0]     \n",
            "                                                                 batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 128, 128, 64) 6720        batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 128, 128, 64) 192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 64, 64, 35)   80640       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 128, 128, 64) 192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 128, 128, 64) 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 64, 64, 35)   105         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 128, 128, 64) 0           batch_normalization_24[0][0]     \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 64, 64, 35)   0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 128, 128, 64) 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 64, 64, 71)   22365       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 128, 128, 64) 256         activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 64, 64, 71)   213         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 128, 128, 64) 36864       batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 64, 64, 71)   0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 128, 128, 64) 4096        batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 128, 128, 64) 192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 64, 64, 106)  67734       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 128, 128, 64) 192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 128, 128, 64) 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 64, 64, 106)  318         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 128, 128, 64) 0           batch_normalization_27[0][0]     \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 64, 64, 106)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 128, 128, 64) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 64, 64, 212)  54272       concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 64, 64, 212)  0           activation_44[0][0]              \n",
            "                                                                 activation_45[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 128, 128, 64) 256         activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 256, 256, 32) 14688       batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 64, 64, 212)  636         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 64, 64, 212)  848         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 128, 128, 64) 36864       batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 256, 256, 32) 1632        batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 256, 256, 32) 96          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 64, 64, 212)  0           batch_normalization_68[0][0]     \n",
            "                                                                 batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 128, 128, 64) 4096        batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 128, 128, 64) 192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 256, 256, 32) 96          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 256, 256, 32) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 64, 64, 212)  0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 128, 128, 64) 192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 128, 128, 64) 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256, 256, 32) 0           batch_normalization_6[0][0]      \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 64, 64, 212)  848         activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 128, 128, 64) 0           batch_normalization_30[0][0]     \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 256, 256, 32) 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 64) 54336       batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 128, 128, 64) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 256, 256, 32) 128         activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 128, 128, 64) 192         conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 128, 128, 64) 256         activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 256, 256, 32) 9216        batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 128, 128, 128 0           batch_normalization_74[0][0]     \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 256, 256, 32) 1024        batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 256, 256, 32) 96          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 128, 128, 17) 19584       concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 256, 256, 32) 96          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 256, 256, 32) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 128, 128, 17) 51          conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 256, 256, 32) 0           batch_normalization_9[0][0]      \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 128, 128, 17) 0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 256, 256, 32) 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 128, 128, 35) 5355        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 256, 256, 32) 128         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 128, 128, 35) 105         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 256, 256, 32) 9216        batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 128, 128, 35) 0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 256, 256, 32) 1024        batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 256, 256, 32) 96          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 128, 128, 53) 16695       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 256, 256, 32) 96          conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 256, 256, 32) 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 128, 128, 53) 159         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 256, 256, 32) 0           batch_normalization_12[0][0]     \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 128, 128, 53) 0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 256, 256, 32) 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 128, 128, 105 13440       concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 128, 128, 105 0           activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 256, 256, 32) 128         activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 128, 128, 105 315         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 128, 128, 105 420         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 256, 256, 32) 9216        batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 128, 128, 105 0           batch_normalization_75[0][0]     \n",
            "                                                                 batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 256, 256, 32) 1024        batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 256, 256, 32) 96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 128, 128, 105 0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 256, 256, 32) 96          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 256, 256, 32) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 128, 128, 105 420         activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 256, 256, 32) 0           batch_normalization_15[0][0]     \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 32) 13472       batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 256, 256, 32) 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 256, 256, 32) 96          conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 256, 256, 32) 128         activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 256, 256, 64) 0           batch_normalization_81[0][0]     \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 256, 256, 8)  4608        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 256, 256, 8)  24          conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 256, 256, 8)  0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 256, 256, 17) 1224        activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 256, 256, 17) 51          conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 256, 256, 17) 0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 256, 256, 26) 3978        activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 256, 256, 26) 78          conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 256, 256, 26) 0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 256, 256, 51) 3264        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 256, 256, 51) 0           activation_52[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 256, 256, 51) 153         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 256, 256, 51) 204         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 256, 256, 51) 0           batch_normalization_82[0][0]     \n",
            "                                                                 batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 256, 256, 51) 0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 256, 256, 51) 204         activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 256, 256, 1)  51          batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 256, 256, 1)  3           conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 256, 256, 1)  0           batch_normalization_88[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 7,264,190\n",
            "Trainable params: 7,238,708\n",
            "Non-trainable params: 25,482\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZYgI2fy0pbJ"
      },
      "source": [
        "##Save Logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly3egaA5nIWw"
      },
      "source": [
        "fp = open('models/log.txt','w')\n",
        "fp.close()\n",
        "fp = open('models/best.txt','w')\n",
        "fp.write('-1.0')\n",
        "fp.close()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyxTlx6L0sZC"
      },
      "source": [
        "##Run Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMNN-bpSnJ18"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  trainStep(model , X_train, Y_train, X_test, Y_test, epochs=200, batchSize = 10 )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}